{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import pandas as pd\n",
    "import glob\n",
    "import torch\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pdb\n",
    "import matplotlib.pyplot as plt\n",
    "import codecs\n",
    "\n",
    "from facenet_pytorch import MTCNN\n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout,ReLU,BatchNormalization, SeparableConv2D \n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.config.list_physical_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_small_csv_paths = 'C:\\\\Users\\\\96291\\\\Desktop\\\\Mini_challenge\\\\un_ziped\\\\purdue-face-recognition-challenge-2024\\\\train.csv'\n",
    "# contains training images with file names of the form n.jpg\n",
    "category_path = 'C:\\\\Users\\\\96291\\\\Desktop\\\\Mini_challenge\\\\un_ziped\\\\purdue-face-recognition-challenge-2024\\\\category.csv'\n",
    "\n",
    "\n",
    "train_data = pd.read_csv(train_small_csv_paths, encoding = 'latin1') \n",
    "numerical_labels = pd.read_csv(category_path, encoding = 'ISO-8859-1')\n",
    "print(numerical_labels)\n",
    "\n",
    "# Create a dictionary for category to numerical label mapping\n",
    "#categpry should be at lefe, because use category to find the numerical_labels. \n",
    "category_to_label = dict(zip( numerical_labels['Category'], numerical_labels['Unnamed: 0']))\n",
    "\n",
    "# Load image data and replace string labels with numerical labels\n",
    "train_data['NumericalLabel'] = train_data['Category'].map(category_to_label)\n",
    "print(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create labels for each file in cvs file\n",
    "train_y = train_data['NumericalLabel']\n",
    "print(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'train_data' is your DataFrame containing all the data\n",
    "train_df, val_df = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "#split for training and validation. \n",
    "\n",
    "# Enhanced data augmentation for training data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Only rescaling for validation data, no augmentation\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory='C:\\\\Users\\\\96291\\\\Desktop\\\\Mini_challenge\\\\un_ziped\\\\test_croped_face',\n",
    "    x_col='File Name',\n",
    "    y_col='NumericalLabel',\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='raw',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    directory='C:\\\\Users\\\\96291\\\\Desktop\\\\Mini_challenge\\\\un_ziped\\\\test_croped_face',\n",
    "    x_col='File Name',\n",
    "    y_col='NumericalLabel',\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='raw',\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_recg = Sequential([\n",
    "    Conv2D(64, (3, 3), padding = 'same', input_shape=(128, 128, 3)),\n",
    "    ReLU(),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2, 2),\n",
    "\n",
    "    Conv2D(64, (3, 3), padding = 'same'),\n",
    "    ReLU(),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2, 2),\n",
    "\n",
    "    Conv2D(128, (3, 3), padding = 'same'),\n",
    "    ReLU(),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2, 2),\n",
    "\n",
    "    Conv2D(128, (3, 3), padding = 'same'),\n",
    "    ReLU(),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2, 2),\n",
    "\n",
    "    Conv2D(256, (3, 3), padding = 'same'),\n",
    "    ReLU(),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2, 2),\n",
    "\n",
    "    Conv2D(256, (3, 3), padding = 'same'),\n",
    "    ReLU(),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2, 2),\n",
    "\n",
    "    Conv2D(512, (3, 3), padding = 'same'),\n",
    "    ReLU(),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2, 2),\n",
    "\n",
    "    # Conv2D(512, (3, 3), padding = 'same'),\n",
    "    # ReLU(),\n",
    "    # BatchNormalization(),\n",
    "    # MaxPooling2D(2, 2),\n",
    "\n",
    "    # Conv2D(1024, (3, 3), padding = 'same'),\n",
    "    # ReLU(),\n",
    "    # BatchNormalization(),\n",
    "    # MaxPooling2D(2, 2),\n",
    "\n",
    "\n",
    "    Flatten(),\n",
    "    #Dense(512),\n",
    "    ReLU(),\n",
    "    Dropout(0.5),\n",
    "    BatchNormalization(),\n",
    "    Dense(100, activation='softmax')  # Assuming 100 classes from 0-99\n",
    "])\n",
    "\n",
    "face_recg.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "face_recg.fit(train_generator, epochs=70, validation_data= val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "model = face_recg\n",
    "\n",
    "# Initialize MTCNN for face detection\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "mtcnn = MTCNN(keep_all=False, device=device)\n",
    "\n",
    "# Directory containing test images\n",
    "test_images_folder = 'C:\\\\Users\\\\96291\\\\Desktop\\\\Mini_challenge\\\\un_ziped\\\\test'\n",
    "\n",
    "# Load category names from your category mapping file\n",
    "category_df = pd.read_csv('C:\\\\Users\\\\96291\\\\Desktop\\\\Mini_challenge\\\\un_ziped\\\\purdue-face-recognition-challenge-2024\\\\category.csv')\n",
    "category_mapping = dict(zip(category_df['Unnamed: 0'], category_df['Category']))\n",
    "\n",
    "# Process images and classify\n",
    "results = []\n",
    "# test_images = sorted(os.listdir(test_images_folder))  # Sort to ensure order\n",
    "test_images = sorted([file for file in os.listdir(test_images_folder) if not file.startswith('._')])\n",
    "\n",
    "for img_name in test_images:\n",
    "    if img_name.lower().endswith('.jpg'):\n",
    "        img_path = os.path.join(test_images_folder, img_name)\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        # Detect the face\n",
    "        boxes, _ = mtcnn.detect(img)\n",
    "        if boxes is not None and len(boxes) > 0:\n",
    "            # Crop the detected face\n",
    "            face = img.crop(boxes[0])\n",
    "            face = face.resize((128, 128))\n",
    "            face_array = np.array(face) / 255.0\n",
    "            face_array = np.expand_dims(face_array, axis=0)\n",
    "\n",
    "            # Classify the face\n",
    "            prediction = model.predict(face_array)\n",
    "            predicted_index = np.argmax(prediction, axis=1)[0]\n",
    "            predicted_category = category_mapping.get(predicted_index, 'Unknown')\n",
    "        else:\n",
    "            predicted_category = 'Unknown'\n",
    "\n",
    "        file_id = int(os.path.splitext(img_name)[0])  # Convert filename to integer for sorting\n",
    "        results.append({'Id': file_id, 'Category': predicted_category})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort results by 'Id' to ensure correct order\n",
    "results_df = pd.DataFrame(results).sort_values(by='Id')\n",
    "results_df['Id'] = results_df['Id'].astype(str)  # Convert back to string if necessary\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv('C:\\\\Users\\\\96291\\\\Desktop\\\\Mini_challenge\\\\un_ziped\\\\predict.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
